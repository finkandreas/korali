#pragma once

#include "modules/distribution/univariate/normal/normal.hpp"
#include "modules/problem/reinforcementLearning/continuous/continuous.hpp"
#include "modules/solver/agent/continuous/continuous.hpp"

__startNamespace__;

class __className__ : public __parentClassName__
{
  public:
  /**
   * @brief Pointer to training the actor network
   */
  learner::DeepSupervisor *_policyLearner;

  /**
   * @brief Korali experiment for obtaining the agent's action
   */
  korali::Experiment _policyExperiment;

  /**
   * @brief Pointer to actor's experiment problem
   */
  problem::SupervisedLearning *_policyProblem;
  
  /**
   * @brief Pointer to training the critic network
   */
  learner::DeepSupervisor *_criticLearner;

  /**
   * @brief Korali experiment for obtaining the q value
   */
  korali::Experiment _criticExperiment;

  /**
   * @brief Pointer to critic experiment problem
   */
  problem::SupervisedLearning *_criticProblem;

  /**
   * @brief Update the V-target or current and previous experiences in the episode
   * @param expId Current Experience Id
   */
  void updateVtbc(size_t expId);

  /**
   * @brief Calculates the gradients for the critic neural network
   * @param miniBatch The indexes of the experience mini batch
   */
  void calculateCriticGradient(const std::vector<size_t> &miniBatch);
  
  /**
   * @brief Calculates the gradients for the policy neural network
   * @param sampledStateActionSequence Sampled state action sequences for policy update
   * @param miniBatch The indexes of the experience mini batch
   */
  void calculatePolicyGradient(const std::vector<std::vector<std::vector<float>>> &sampledStateActionSequence, const std::vector<size_t> &miniBatch);
 
  std::vector<policy_t> runPolicy(const std::vector<std::vector<std::vector<float>>> &stateActionBatchSequence) override;
 
  /**
   * @brief Sample new set of actions for given state batch sequence
   * @param stateActionBatchSequence The indexes of the experience mini batch
   */
  std::vector<std::vector<std::vector<float>>> sampleStateActionBatchSequence(const std::vector<size_t> &miniBatch);

  /**
   * @brief [Statistics] Keeps track of the max policy mu of the current minibatch for each action variable
   */
  std::vector<float> _maxMiniBatchPolicyMean;

  /**
   * @brief [Statistics] Keeps track of the max policy sigma of the current minibatch for each action variable
   */
  std::vector<float> _maxMiniBatchPolicyStdDev;

  /**
   * @brief [Statistics] Keeps track of the min policy mu of the current minibatch for each action variable
   */
  std::vector<float> _minMiniBatchPolicyMean;

  /**
   * @brief [Statistics] Keeps track of the min policy sigma of the current minibatch for each action variable
   */
  std::vector<float> _minMiniBatchPolicyStdDev;

  knlohmann::json getAgentPolicy() override;
  void setAgentPolicy(const knlohmann::json &hyperparameters) override;
  void trainPolicy() override;
  void printAgentInformation() override;
  void initializeAgent() override;
};

__endNamespace__;
